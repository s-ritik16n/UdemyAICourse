{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9e2229e-d428-4010-9d57-22fb4888e978",
   "metadata": {},
   "source": [
    "# NLTK"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ccc310-92d0-45b5-b98d-9260799fabb5",
   "metadata": {},
   "source": [
    "**NLTK is a package used for performing operations on text-based datasets, also known as text preprocessing. These operations include -**\n",
    "\n",
    "- Lowercasing\n",
    "- Removing Stop words\n",
    "- Using regex to find patterns, remove unwanted characters/strings, etc\n",
    "- Tokenization\n",
    "- Stemming\n",
    "- Lemmatization\n",
    "- Creating/Analyzing N-grams"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cadcb3f-7491-4461-afc3-fd019ed440ef",
   "metadata": {},
   "source": [
    "### Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "02cef231-6a36-4b5d-a66f-f3b098fc8ff9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /Users/ritik_saxena/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt_tab')\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fe85bc1f-2f6b-4fda-9f65-e6b8611c75ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = \"Her cat's name is Luna. Her dog's name is Max\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4a80a8a1-70d3-4ee0-8041-a1996010fe93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Her cat's name is Luna.\", \"Her dog's name is Max\"]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_tokenize(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f8ae4c75-86bb-4436-a1a6-5022e953e6f0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Her',\n",
       " 'cat',\n",
       " \"'s\",\n",
       " 'name',\n",
       " 'is',\n",
       " 'Luna',\n",
       " '.',\n",
       " 'Her',\n",
       " 'dog',\n",
       " \"'s\",\n",
       " 'name',\n",
       " 'is',\n",
       " 'Max']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokenize(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ceed2074-356a-4498-97ba-ce8f4c94e259",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Her cat's name is Luna.\", \"Her dog's name is Max\"]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_tokenize(sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f96f21a-ee56-48c4-947b-e76855730ba1",
   "metadata": {},
   "source": [
    "### Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9a253888-06b7-4807-914b-77db025c7916",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "ps = PorterStemmer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b674022e-2821-4684-ba99-bf675bfac364",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "connnecting : connnect\n",
      "connect : connect\n",
      "connected : connect\n",
      "conn : conn\n"
     ]
    }
   ],
   "source": [
    "connect_tokens = [\"connnecting\", \"connect\", \"connected\", \"conn\"]\n",
    "for tok in connect_tokens:\n",
    "    print(f\"{tok} : {ps.stem(tok)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8c1dfba-2897-46a4-b027-20b5096e0102",
   "metadata": {},
   "source": [
    "### Lemmatization\n",
    "\n",
    "Lemmatizing preserves the context of the word as it is used, unlike stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7c08a359-6939-4f87-adde-5f45fdd59178",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/ritik_saxena/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "22c7a577-d994-48bb-b71d-8e3cb5549242",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "lm = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "26d06a11-b31c-4bce-bc24-46c9d667d7ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "connnecting: connnecting\n",
      "connect: connect\n",
      "connected: connected\n",
      "conn: conn\n"
     ]
    }
   ],
   "source": [
    "for tok in connect_tokens:\n",
    "    print(f\"{tok}: {lm.lemmatize(tok)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6b3d782c-fd3c-4249-8f04-c410f2ef7d03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learners - learner\n"
     ]
    }
   ],
   "source": [
    "print(f\"learners - {lm.lemmatize('learners')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36707210-5bb0-4148-b40a-d356e7d2e015",
   "metadata": {},
   "source": [
    "### N-grams\n",
    "\n",
    "N-grams help us analyze the relationship between neighboring words. Example - unigrams, bigrams, trigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5402cf55-8298-4d38-a68a-6a9d60f48260",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib is building the font cache; this may take a moment.\n"
     ]
    }
   ],
   "source": [
    "import nltk, pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c77fbce0-fb1a-45dd-afaa-fd4926a7488d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(the,)             1\n",
      "(rise,)            1\n",
      "(of,)              1\n",
      "(aritifical,)      1\n",
      "(intelligence,)    1\n",
      "(has,)             1\n",
      "(led,)             1\n",
      "(to,)              1\n",
      "(advancements,)    1\n",
      "(in,)              1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "tokens = [\"the\", \"rise\", \"of\", \"aritifical\", \"intelligence\", \"has\", \"led\", \"to\", \"advancements\", \"in\", \"computer\", \"vision\"]\n",
    "n=1\n",
    "unigrams = (pd.Series(nltk.ngrams(tokens, n)).value_counts())\n",
    "print(unigrams[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "370547a7-d8a2-41b6-a98b-032b6c47676f",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "***If you change the value of `n` to 2, it'll be frequency of occurence of bigrams, and so on..***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f38deb-0f88-4e67-9c12-828ee7ebe648",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_course_env",
   "language": "python",
   "name": "nlp_course_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
